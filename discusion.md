### Trade-offs:
Para este caso, una de las principales ventajas es la escalabilidad y el desacoplamiento, esto dado que al ser los subscribers los que "muestran interés" (calculan la distancia) permite repartir la carga, por otro lado, el hecho de trabajar con mensajes que lleven la mínima información posible reducirá el tráfico en la red, así como la carga en RabbitMQ sin embargo, un problema que puede traer esto es que en caso de haber un sismo que sea de interés para muchos subscribers, por ejemplo un sismo de gran magnitud y que esté cerca (en su radio de km) de un gran conjunto de subscriber, puede sobrecargar la api al recibir muchas consultas HTTP, haciendo la misma consulta.

Este enfoque implica un trade-off importante: al simplificar los mensajes publicados y delegar el cálculo en cada subscriber, se gana en desacoplamiento y flexibilidad, pero se sacrifica eficiencia global y control centralizado, ya que cada subscriber puede repetir parte del trabajo (consultas a la API).

Además, existe un trade-off entre la simplicidad del formato de mensaje y su evolución en el tiempo. El uso de un formato posicional y ultra ligero en base de texto (id|lat|lon|mag|ts) minimiza ancho de banda y complejidad, pero lo vuelve frágil ante cambios (agregar/quitar campos rompe parsers) y hay que tener un acuerdo previo entre los subscribers, la api y el publisher para ver que datos se van a enviar, debido a la falta de etiquetados como lo haríamos por ejemplo con una respuesta en formato JSON. Para mitigarlo, habría que pasar a un formato key=value con pipes (id=…|lat=…|…) que preserve compatibilidad y permita extender el esquema sin impactar a los suscriptores existentes si es que ocurren cambios, pero esto iría en contra de la simplicidad y eficiencia del mensaje.

Adicionalmente, con una entrega at-least-once como en RabbitMQ, hay un trade-off importante entre robustez y duplicados: el sistema garantiza que los mensajes no se pierdan, pero a cambio un mismo evento puede procesarse más de una vez. Esto implica que los subscribers y la API debería tal vez implementar mecanismos de idempotencia, como el uso del identificador único del sismo para descartar duplicados, cachear consultas recientes o evitar llamadas repetidas. Se gana resiliencia y tolerancia a fallos, pero se traslada la complejidad a los extremos, que deben manejar estos casos de manera explícita.

### Back of the Envelope:
Comenzando con los sismos, en chile en promedio se producen 200 sismos al día, eso se traduce en aproximadamente 1 sismo cada 7.2 minutos, esto nos indica que la carga de computo en los subscribers sera baja, casi despreciable. Con respecto al número de subscribers tenemos que chile tiene un total de 346 comunas, por lo que podemos estimar que deberían haber al menos unos 346 subscribers, luego tenemos que chile tiene 4270 km de largo por lo que un sismo relativamente central tendría aproximadamente 81 comunas dentro del radio de 500km (asumiendo distribución equitativa), es decir, la api debe se capaz de procesar ~100 consultas en ~5 minutos(dejando algo de margen).