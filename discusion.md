### Trade-offs:
Para este caso, una de las principales ventajas es la escalabilidad y el desacoplamiento, esto dado que al ser los subscribers los que "muestran interés" (calculan la distancia) permite repartir la carga, por otro lado, el hecho de trabajar con mensajes que lleven la mínima información posible reducirá el tráfico en la red, así como la carga en RabbitMQ sin embargo, un problema que puede traer esto es que en caso de haber un sismo que sea de interés para muchos subscribers, por ejemplo un sismo de gran magnitud y que esté cerca (en su radio de km) de un gran conjunto de subscriber, puede sobrecargar la api al recibir muchas consultas HTTP, haciendo la misma consulta.

Este enfoque implica un trade-off importante: al simplificar los mensajes publicados y delegar el cálculo en cada subscriber, se gana en desacoplamiento y flexibilidad, pero se sacrifica eficiencia global y control centralizado, ya que cada subscriber puede repetir parte del trabajo (consultas a la API).

Además, existe un trade-off entre la simplicidad del formato de mensaje y su evolución en el tiempo. El uso de un formato posicional y ultra ligero en base de texto (id|lat|lon|mag|ts) minimiza ancho de banda y complejidad, pero lo vuelve frágil ante cambios (agregar/quitar campos rompe parsers) y hay que tener un acuerdo previo entre los subscribers, la api y el publisher para ver que datos se van a enviar, debido a la falta de etiquetados como lo haríamos por ejemplo con una respuesta en formato JSON. Para mitigarlo, habría que pasar a un formato key=value con pipes (id=…|lat=…|…) que preserve compatibilidad y permita extender el esquema sin impactar a los suscriptores existentes si es que ocurren cambios, pero esto iría en contra de la simplicidad y eficiencia del mensaje.

Adicionalmente, con una entrega at-least-once como en RabbitMQ, hay un trade-off importante entre robustez y duplicados: el sistema garantiza que los mensajes no se pierdan, pero a cambio un mismo evento puede procesarse más de una vez. Esto implica que los subscribers y la API debería tal vez implementar mecanismos de idempotencia, como el uso del identificador único del sismo para descartar duplicados, cachear consultas recientes o evitar llamadas repetidas. Se gana resiliencia y tolerancia a fallos, pero se traslada la complejidad a los extremos, que deben manejar estos casos de manera explícita.

### Back of the Envelope:
El uso de un cálculo tipo Back of the Envelope nos permitiría estimar la carga que el sistema debería o podría soportar y en base a esto justificar la elección de la arquitectura. Por ejemplo se sabe que en chile ocurren entre unos 150 a 200 sismos diarios, lo que implica un evento cada pocos minutos. Con esta información, se puede calcular la frecuencia con que los subscribers podrían recibir notificaciones y cuántos de ellos estarían dentro del radio de interés de 500 km.

Ya que sabemos la cantidad de subscribers (1 por cada una de las 5 ciudades en este caso), podríamos calcular la cantidad de subscribers que estarían a la escucha de los mensajes de evento, sin embargo, no podríamos hacer un cálculo rápido de cuantos de estos subscribers recibirían un sismo de interés, dado que los eventos de los sismos pueden ocurrir en cualquier parte a lo largo del país y quedar fuera del radio de todos o solo de algunos, habría que hacer un estudio de cuantos sismos caen en el radio de cada subscriber, para estimar una mejor carga de llamados a la api. Además que las ciudades de Arica y Punta Arenas están más a los extremos del país, mientras que Coquimbo, Valparaíso y Concepción están más centrados, por lo que estos 3 al estar más cerca de la mitad del país tendrían más posibilidades de recibir un sismo de interés, y hacer cada uno la misma consulta a la API.
Pero dado que el número total de subscribers en este escenario es reducido y las consultas hacia la API se limitan a casos en los que un sismo efectivamente cae dentro del radio de 500 km, la carga generada sería baja y fácilmente manejable. Incluso en situaciones donde un mismo sismo active a varios subscribers simultáneamente, el volumen de solicitudes concurrentes seguiría siendo lo suficientemente pequeño como para que la arquitectura propuesta lo soporte sin inconvenientes. 

Si se planteara un escenario hipotético con un número mayor de subscribers por ejemplo, uno por cada ciudad mediana/grande o por comunas de chile la probabilidad de que un sismo afecte a múltiples subscribers al mismo tiempo aumentaría considerablemente. En un evento de gran magnitud en la zona central, decenas de subscribers podrían encontrarse dentro del radio de 500 km y todos generarían solicitudes concurrentes hacia la API. Este razonamiento permite anticipar que, aunque la arquitectura actual es suficiente para el caso reducido de cinco subscribers, una expansión a gran escala podría hacernos replantear la arquitectura propuesta, o implementar optimizaciones adicionales, como caches compartidos, mecanismos de deduplicación, alguna capa intermedia que centralice algunas consultas para evitar la sobrecarga del servicio HTTP, también podriamos reducir el radio de 500 km a un valor menor para limitar la cantidad de subscribers que recibirían un sismo de interés, lo que disminuiría la carga en la API. 

<img width="1883" height="623" alt="image" src="https://github.com/user-attachments/assets/4a883447-1253-412b-b666-74aa637ed45e" />

Mapa de sismos de la última semana:
<img width="1305" height="956" alt="image" src="https://github.com/user-attachments/assets/86c895ad-48d0-4304-8e91-c248cf0e4cc4" />

Imagenes por:
- Google Eath
- https://earthquakes.volcanodiscovery.com/map/Chile?L=8

